# Benchmark Results — v0.2.2

**Date:** 2026-02-26  
**Tag:** v0.2.2  
**Base Version:** v0.2.1 (correctness fix: eliminate get/eviction race; optional: read buffer + tryDrain for recency)

---

## Executive Summary

| Metric | Result | Verdict |
|--------|--------|---------|
| Peak throughput (1T) | 23.6M ops/s (mixed) | Good |
| Thread scaling | **Negative** (2T halves throughput vs 1T) | Critical issue |
| Scaling efficiency at 4T | ~14% (vs ideal 4×) | Poor |
| p99 latency | ~15–24 µs (≈200× median) | Tail bottleneck |
| Lock contention | 7–12% RUNNABLE; AQS/HashMap dominate | Contention confirmed |

**Key Finding:** Throughput does not scale linearly with threads; contention dominates by 2T. Tail latencies (p99) are hundreds of times worse than the median (p50 ≈ 83 ns). Stack profiler shows most time in WAITING/TIMED_WAITING and lock/cache code when RUNNABLE. This matches Phase 5 expectations: *O(1) algorithms don't scale linearly under contention* and *tail latency reveals hidden bottlenecks*.

---

## Benchmark Design Philosophy

### Goals

The benchmark suite is designed to answer three questions:

1. **How does throughput scale with thread count?** — Does adding threads improve ops/sec, or does lock contention dominate?
2. **How do workload patterns affect performance?** — Read-heavy vs write-heavy vs mixed.
3. **Where are the bottlenecks?** — Lock contention, cache misses, or algorithmic overhead.

### Why JMH?

JMH (Java Microbenchmark Harness) is used because:

- **Warmup handling** — JIT compilation artifacts are excluded from measurements
- **Statistical rigor** — Multiple iterations with variance reporting
- **Dead code elimination prevention** — `Blackhole` consumes results to prevent JIT optimization
- **Thread coordination** — Built-in support for multi-threaded benchmarks

### Workload Design Rationale

| Workload | Read % | Write % | Key Distribution | Purpose |
|----------|--------|---------|------------------|---------|
| `readHeavy` | 100% | 0% | Within capacity (0–9,999) | Measure read throughput, relaxed LRU effectiveness |
| `writeHeavy` | 0% | 100% | Beyond capacity (0–99,999) | Stress eviction path, expose lock contention |
| `mixed` | 50% | 50% | Both distributions | Realistic workload, reader-writer interaction |

**Key space rationale:**
- `readHeavy`: Keys 0–9,999 (all pre-loaded, 100% hit rate) — isolates read path performance
- `writeHeavy`: Keys 0–99,999 with capacity 10,000 — guarantees evictions on ~90% of writes

---

## Cache Design Under Test

### Locking Strategy (v0.2.2)

- **get():** Holds `mapLock` only for map lookup (or, in a variant, holds `mapLock` through `tryLock(listLock)` + move to head to avoid eviction race). Recency updates may be deferred via a read buffer and drained by `tryDrain()`.
- **put():** `mapLock` then `listLock`; full eviction and DLL update under both locks.

Invariants: map and DLL stay in sync; eviction removes from DLL then map; map lock is acquired before list lock.

### Relaxed LRU Semantics

Recency updates on read are best-effort (e.g. tryLock or buffer+drain). Writes always update recency. Trade-off: throughput over perfect LRU ordering.

---

## Benchmark Results

### Configuration

```
JMH Version: 1.37
Runs: benchmarks module (shaded JAR), forked
Warmup: 5 iterations × 2s
Measurement: 15 iterations × 3s (throughput) / sample (latency)
Threads: 1, 2, 4, 8 (throughput); 4 (latency, profilers)
Fork: 3 (throughput/latency); 0 (profilers, in-process)
```

### Throughput (ops/sec) — Thread Scaling

| Benchmark | 1 Thread | 2 Threads | 4 Threads | 8 Threads |
|-----------|----------|-----------|-----------|-----------|
| `mixed` | **23.6M** ± 0.4M | 12.9M ± 0.2M | 13.4M ± 0.2M | 13.8M ± 0.4M |
| `readHeavy` | **22.8M** ± 0.9M | 24.8M ± 0.1M* | 12.9M ± 0.8M | 14.7M ± 0.5M |
| `writeHeavy` | **21.2M** ± 0.2M | 11.1M ± 1.1M | 11.8M ± 0.5M | 11.9M ± 0.8M |

\* readHeavy at 2T is an outlier (measurement/workload quirk).

### Thread Scaling Visualization

```
Throughput (M ops/s)
     │
  25 ┤ ●────●                              readHeavy (1T, 2T outlier)
     │  \    \
  23 ┤   ●    \                            mixed 1T
     │    \    \  ●──●──●
  21 ┤     ●    \      \                   writeHeavy 1T
     │      \    ●      ●──●──●
  14 ┤       \   \  ●──●                    mixed/readHeavy 4T/8T
     │        \   ●──●──●                   writeHeavy 2T+
  11 ┤
     │
   0 └────┬────┬────┬────┬────
          1    2    4    8   threads
```

### Key Observations (Throughput)

1. **1T baseline is highest** — mixed ~23.6M, readHeavy ~22.8M, writeHeavy ~21.2M ops/s.
2. **2T halves throughput for mixed and writeHeavy** — adding a second thread does not double throughput; contention dominates.
3. **4T / 8T plateau** — mixed/readHeavy ~13–15M, writeHeavy ~11–12M. Doubling threads from 4 to 8 does not double ops/s.
4. **Linear scaling would imply ~8× at 8T** — observed 8T is below 1T and flat; *O(1) per-op does not translate to linear scaling under contention*.

### Scaling Efficiency

| Benchmark | Ideal 4× (from 1T) | Actual 4T | Efficiency |
|-----------|-------------------|-----------|------------|
| `mixed` | 94.3M | 13.4M | **~14%** |
| `readHeavy` | 91.1M | 12.9M | **~14%** |
| `writeHeavy` | 84.6M | 11.8M | **~14%** |

---

## Latency Distribution (p50 / p95 / p99)

SampleTime mode, 4 threads; unit ns/op.

| Benchmark | p50 (median) | p90 | p95 | p99 | p99.99 | max |
|-----------|--------------|-----|-----|-----|--------|-----|
| `mixed` | 83 | 125 | 208 | 20 992 | 69 248 | ~10 ms |
| `readHeavy` | 83 | 292 | 667 | 15 280 | 57 856 | ~52 ms |
| `writeHeavy` | 83 | 125 | 209 | 23 744 | 72 835 | ~11 ms |

### Key Observations (Latency)

- **Median (p50)** — ~83 ns/op for all workloads; fast path is sub-100 ns.
- **p99 is ~180–280× the median** — 15–24 µs vs 83 ns; a small fraction of operations wait much longer (locks, GC, scheduling).
- **Tail latency reveals hidden bottlenecks** — the median hides contention and stalls that show up in p99 and beyond.

---

## Lock Contention (Stack Profiler)

In-process runs (`-f 0`) with `-prof stack:lines=5` on readHeavy and writeHeavy (4 threads).

### Thread State Distribution

| Workload | WAITING | TIMED_WAITING | RUNNABLE |
|----------|---------|---------------|----------|
| readHeavy | 64.4% | 23.5% | **12.1%** |
| writeHeavy | 66.0% | 26.6% | **7.3%** |

Only 7–12% of samples are RUNNABLE; the rest are blocked or waiting.

### RUNNABLE Hot Spots

- **readHeavy:** `LRUCache.tryDrain`/get, `ReentrantLock.unlock`, `HashMap.get`, `AbstractQueuedSynchronizer.acquireQueued` (lock acquisition), `ConcurrentLinkedQueue.offer`/poll.
- **writeHeavy:** `ReentrantLock.unlock`, `HashMap.hash`/remove/put, `LRUCache.put`, `AbstractQueuedSynchronizer.acquireQueued`.

### WAITING (Lock Contention)

- **readHeavy:** ~11.4% of samples in `AbstractQueuedSynchronizer.acquireQueued` (waiting to acquire lock).
- **writeHeavy:** ~19.3% in `AbstractQueuedSynchronizer.acquireQueued` — write path spends more time waiting on locks and less time RUNNABLE than readHeavy.

**Interpretation:** Lock acquisition (AQS) and cache/HashMap code dominate. Write-heavy workload contends more on the same locks, consistent with lower throughput and higher tail latency for writes.

---

## Interpretation Summary

### Finding 1: No Linear Scaling (Contention)

Adding threads does not scale throughput; it often reduces it. By 2T, mixed and writeHeavy drop to roughly half of 1T. By 4T/8T, throughput plateaus. Contention on shared locks (map + list, and any buffer/drain path) dominates.

### Finding 2: Tail Latency Exposes Bottlenecks

p99 is hundreds of times worse than p50. Occasional long waits (lock contention, GC, scheduler) are hidden by the median and show up in the tail.

### Finding 3: Profiler Confirms Lock and Cache Hot Spots

Stack profiler shows most time in WAITING/TIMED_WAITING; when RUNNABLE, time is in AQS (lock unlock/acquire), HashMap, and LRUCache get/put/tryDrain. Write path is more lock-bound than read path.

### Next Steps (Phase 6)

- Reduce contention: split locks, read-write locks, or per-segment locking.
- Re-benchmark after design changes to measure improvement in scaling and tail latency.

---

## Commands to Reproduce

```bash
# Build benchmarks JAR (from repo root)
mvn clean install -DskipTests
# or: mvn -pl benchmarks package

# Throughput + thread scaling (1T, 2T, 4T, 8T)
java -jar benchmarks/target/benchmarks.jar -f 3 -wi 5 -i 15 -t 1
java -jar benchmarks/target/benchmarks.jar -f 3 -wi 5 -i 15 -t 2
java -jar benchmarks/target/benchmarks.jar -f 3 -wi 5 -i 15 -t 4
java -jar benchmarks/target/benchmarks.jar -f 3 -wi 5 -i 15 -t 8

# Latency (p50/p95/p99)
java -jar benchmarks/target/benchmarks.jar -f 3 -wi 5 -i 5 -t 4 -bm sampletime -tu ns

# Lock/stack profiler (from cache-engine, -f 0)
cd cache-engine
mvn test-compile exec:java -Dexec.args="-f 0 -wi 3 -i 3 -t 4 -prof stack:lines=5 org.jerome.benchmark.LRUCacheBenchmark.readHeavy"
mvn test-compile exec:java -Dexec.args="-f 0 -wi 3 -i 3 -t 4 -prof stack:lines=5 org.jerome.benchmark.LRUCacheBenchmark.writeHeavy"
```

Full raw data and analysis: `benchmarks/RESULTS.md`.
